Go order is currently not respected
    Asked copilot to fix it but it doesn't seem able to
    Need to write a test in crib_engine to play 2 full rounds
    Mock the deck and starter, check that go is respected
    Once it's working in crib engine, then we need to check that it's working in the API

    Also had an instance after go was reached where I played my last card of 10, beginner
        had 4 and 9 left, and it chose to play the 4. When I went to add a test in to
        test_beginner_player, it does the correct thing. So the problem is either with the
        table being reset, or in the API



running on 8001
- get everything working, check that a game is saved to the database
- play against the beginner player, see if you can actually win or not

- we'll see how fast the exact one is calculating
    - can probably do something clever with the 4 card one
    - problem, given 6 cards, calculate the hand avearge of the 4 cards discarding all 15 combinatios of 2 cards
    - probsem 2, doing it this way causes 20 million rows when we have each row as the 6 card combination
    - with 4 cards it's only 200 000
    - so imagine we have the 4 card combinations way
        Initially for each 4 card combination we added ecah possible starter card, got the min,max and average of the hand
        Can we create now a pandas group where 2 of the starter cards are not included in each group


# python .\scripts\generate_il_data.py --games 10000 --out_dir "il_datasets/"
# python .\scripts\train_linear_models.py --data_dir "il_datasets/" --out_dir models --epochs 20
# python scripts/benchmark_neural_vs_reasonable.py --games 500 --models_dir models

Need to test that seeded cribbage game does not play the same game every round



testing strategies
    because using statistics increases average pegging points only by about 2
    where starting with crib increase it by about 6 to 7
    then using statistics the whole time is worse because it doesn't account for the end of the game

    something wrong with my min_total_score calculation, should be winning 50% of the time against beginner player
    need to run find_strategy_discard_differences.py, then check

    start experiments folder 


Need to check that test_medium_player passes
    hand_scores table is not correct, well cards in hand 3H|4H|5H|6H
    but in the scores table AS|3H|4H|5H|6H = 8 because starter is 6H
    So the hand_scores is not wrong, but maybe doesn't include everything, I dunno
    I look up hand_stats_approx hand_key="3H|4H|5H|6H" which has the wrong min score

after 1 game, average pegging 3.4, average hand 7.1

def test_get_6_card_stats_df_is_correct():
    # manually checked calculations using a crib app
    hand = build_hand(["3h","4h","5h","6h","7h","8h"])
    # the minimum is 12, but my db shows 10, it's because 3,4,5,6 and 5,6,7,8 is the case where any starter gives another 2 points
    df = get_6_card_stats_df(hand, dealer_is_self=True)
    df2 = pd.DataFrame({"hi":[18,19,20,21,22,23,24,25,26,27,28],})
    assert df.equals(df2)